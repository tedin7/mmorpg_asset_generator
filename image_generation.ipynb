{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d847847-254e-4b17-be33-3ee7d2e83d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e30ea1-f49c-457b-aacd-000a504580d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eaad61-2e8a-4d9e-b273-c012c602f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d07ec-4090-4372-974d-cbf45ca101f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora_sdxl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac621fc3-94e7-47fd-97a0-07e31ed4b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets accelerate peft diffusers bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21e949-84f5-4b9c-b5f3-3146e75cb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env bash\n",
    "!accelerate launch train_dreambooth_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
    "  --dataset_name=\"your-dataset-name\" \\\n",
    "  --output_dir=\"output-directory\" \\\n",
    "  --caption_column=\"prompt\" \\\n",
    "  --mixed_precision=\"bf16\" \\\n",
    "  --instance_prompt=\"a highly detailed MMORPG asset\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=32 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --learning_rate=2e-4 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=50 \\\n",
    "  --max_train_steps=1000 \\\n",
    "  --checkpointing_steps=250 \\\n",
    "  --validation_prompt=\"a highly detailed MMORPG character portrait, fantasy race, intricate facial features, game art style, 4k resolution\"\\\n",
    "  --enable_xformers_memory_efficient_attention \\\n",
    "  --dataloader_num_workers=16 \\\n",
    "  --rank=128 \\\n",
    "  --report_to=\"tensorboard\" \\\n",
    "  --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72b4c1-251b-4071-83d3-adf270eddc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, AutoencoderKL, DPMSolverMultistepScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the fine-tuned model\n",
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True\n",
    ")\n",
    "pipe.load_lora_weights(\"charactergen_model_improved\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Enable attention slicing for memory efficiency\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "# Use a more efficient scheduler\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Function to generate and display an image\n",
    "def generate_and_display_image(prompt, num_inference_steps=20):\n",
    "    image = pipe(prompt=prompt, num_inference_steps=num_inference_steps).images[0]\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(prompt)\n",
    "    display(plt.gcf())\n",
    "    plt.close()\n",
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"a highly detailed MMORPG character asset of a noble elven warrior with intricate armor, long flowing hair, and a determined expression, 4k resolution, cinematic lighting\",\n",
    "    \"an MMORPG character asset of a wise old wizard with a long beard and ornate robes, holding a magical staff\",\n",
    "    \"an MMORPG character asset of a stealthy rogue assassin with dark leather armor and a hooded cloak\",\n",
    "    \"an MMORPG character asset of a fierce orc chieftain with tribal markings and imposing battle gear\"\n",
    "]\n",
    "\n",
    "# Generate and display images for each prompt\n",
    "for prompt in test_prompts:\n",
    "    print(f\"Generating: {prompt}\")\n",
    "    generate_and_display_image(prompt)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Demonstrate batch generation\n",
    "def get_inputs(batch_size=1):\n",
    "    generator = [torch.Generator(\"cuda\").manual_seed(i) for i in range(batch_size)]\n",
    "    prompts = batch_size * [test_prompts[0]]  # Using the first prompt for this example\n",
    "    num_inference_steps = 20\n",
    "\n",
    "    return {\"prompt\": prompts, \"generator\": generator, \"num_inference_steps\": num_inference_steps}\n",
    "\n",
    "# Generate a batch of images\n",
    "batch_size = 4  # Adjust based on your GPU capabilities\n",
    "images = pipe(**get_inputs(batch_size=batch_size)).images\n",
    "\n",
    "# Display the batch of images\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Character {i+1}\")\n",
    "plt.tight_layout()\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7abf4-f2df-49a2-8543-ab9743e90a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad140d2-d103-43e8-8b35-cdf18208b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "cache_path = HfFolder.cache_home\n",
    "if os.path.exists(cache_path):\n",
    "    shutil.rmtree(cache_path)\n",
    "    print(f\"Cleared Hugging Face cache at {cache_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbeada-1fcb-4c39-ad67-555e11219f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635152e-1339-4d7f-ac61-1f4a2da2aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get clean\n",
    "!apt-get autoclean\n",
    "!rm -rf /tmp/\n",
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fbb16-9613-446e-8c92-9f57eb33b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find / -maxdepth 1 -type f -size +100M -exec ls -lh {} \\; 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9129ff2-c25f-45da-ba6f-69d1a32f578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Get the cache directory\n",
    "cache_path = HfFolder().cache_dir\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    # List contents before deletion\n",
    "    print(\"Contents of cache directory before deletion:\")\n",
    "    for item in os.listdir(cache_path):\n",
    "        print(item)\n",
    "    \n",
    "    # Remove contents of the cache directory\n",
    "    for item in os.listdir(cache_path):\n",
    "        item_path = os.path.join(cache_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.unlink(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "    \n",
    "    print(f\"\\nCleared contents of Hugging Face cache at {cache_path}\")\n",
    "    \n",
    "    # List contents after deletion\n",
    "    print(\"\\nContents of cache directory after deletion:\")\n",
    "    for item in os.listdir(cache_path):\n",
    "        print(item)\n",
    "else:\n",
    "    print(f\"Hugging Face cache directory not found at {cache_path}\")\n",
    "\n",
    "# Check available space\n",
    "!df -h /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f867-9ec8-4448-8e5f-9725dfe68444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
